{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# University of Stirling\n",
    "\n",
    "# ITNPBD2 Representing and Manipulating Data\n",
    "\n",
    "# Assignment Autumn 2025\n",
    "\n",
    "# A Consultancy Job for JC Penney\n",
    "\n",
    "This notebook forms the assignment instructions and submission document of the assignment for ITNPBD2. Read the instructions carefully and enter code into the cells as indicated.\n",
    "\n",
    "You will need these five files, which were in the Zip file you downloaded from the course webpage:\n",
    "\n",
    "- jcpenney_reviewers.json\n",
    "- jcpenney_products.json\n",
    "- products.csv\n",
    "- reviews.csv\n",
    "- users.csv\n",
    "\n",
    "The data in these files describes products that have been sold by the American retail giant, JC Penney, and reviews by customers who bought them. Note that the product data is real, but the customer data is synthetic.\n",
    "\n",
    "Your job is to process the data, as requested in the instructions in the markdown cells in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completing the Assignment\n",
    "\n",
    "Rename this file to be xxxxxx_BD2 where xxxxxx is your student number, then type your code and narrative description into the boxes provided. Add as many code and markdown cells as you need. The cells should contain:\n",
    "\n",
    "- **Text narrative describing what you did with the data**\n",
    "- **The code that performs the task you have described**\n",
    "- **Comments that explain your code**\n",
    "\n",
    "The final structure (in PDF) of your report must:\n",
    "- **Start from the main insights observed (max 5 pages)**\n",
    "- **Include as an appendix the source code used for producing those insights (max 15 pages)**\n",
    "- **Include an AI cover sheet (provided on Canvas), which must contain a link to a versioned notebook file in OneDrive or another platform for version checks.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marking Scheme\n",
    "The assessment will be marked against the university Common Marking Scheme (CMS)\n",
    "\n",
    "Here is a summary of what you need to achieve to gain a grade in the major grade bands:\n",
    "\n",
    "|Grade|Requirement|\n",
    "|:---|:---|\n",
    "| Fail | You will fail if your code does not run or does not achieve even the basics of the task. You may also fail if you submit code without either comments or a text explanation of what the code does.|\n",
    "| Pass | To pass, you must submit sufficient working code to show that you have mastered the basics of the task, even if not everything works completely. You must include some justifications for your choice of methods, but without mentioning alternatives. |\n",
    "| Merit | For a merit, your code must be mostly correct, with only small problems or parts missing, and your comments must be useful rather than simply re-stating the code in English. Most choices for methods and structures should be explained and alternatives mentioned. |\n",
    "| Distinction | For a distinction, your code must be working, correct, and well commented and shows an appreciation of style, efficiency and reliability. All choices for methods and structures are concisely justified and alternatives are given well thought considerations. For a distinction, your work should be good enough to present to executives at the company.|\n",
    "\n",
    "The full details of the CMS can be found here\n",
    "\n",
    "https://www.stir.ac.uk/about/professional-services/student-academic-and-corporate-services/academic-registry/academic-policy-and-practice/quality-handbook/assessment-policy-and-procedure/appendix-2-postgraduate-common-marking-scheme/\n",
    "\n",
    "Note that this means there are not certain numbers of marks allocated to each stage of the assignment. Your grade will reflect how well your solutions and comments demonstrate that you have achieved the learning outcomes of the task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "When you are ready to submit, **print** your notebook as PDF (go to File -> Print Preview) in the Jupyter menu. Make sure you have run all the cells and that their output is displayed. Any lines of code or comments that are not visible in the pdf should be broken across several lines. You can then submit the file online.\n",
    "\n",
    "Late penalties will apply at a rate of three marks per day, up to a maximum of 7 days. After 7 days you will be given a mark of 0. Extensions will be considered under acceptable circumstances outside your control.\n",
    "\n",
    "## Academic Integrity\n",
    "\n",
    "This is an individual assignment, and so all submitted work must be fully your own work.\n",
    "\n",
    "The University of Stirling is committed to protecting the quality and standards of its awards. Consequently, the University seeks to promote and nurture academic integrity, support staff academic integrity, and support students to understand and develop good academic skills that facilitate academic integrity.\n",
    "\n",
    "In addition, the University deals decisively with all forms of Academic Misconduct.\n",
    "\n",
    "Where a student does not act with academic integrity, their work or behaviour may demonstrate Poor Academic Practice or it may represent Academic Misconduct.\n",
    "\n",
    "### Poor Academic Practice\n",
    "\n",
    "Poor Academic Practice is defined as: \"The submission of any type of assessment with a lack of referencing or inadequate referencing which does not effectively acknowledge the origin of words, ideas, images, tables, diagrams, maps, code, sound and any other sources used in the assessment.\"\n",
    "\n",
    "### Academic Misconduct\n",
    "\n",
    "Academic Misconduct is defined as: \"any act or attempted act that does not demonstrate academic integrity and that may result in creating an unfair academic advantage for you or another person, or an academic disadvantage for any other member or member of the academic community.\"\n",
    "\n",
    "Plagiarism is presenting somebody else’s work as your own **and includes the use of artificial intelligence tools beyond AIAS Level 2 or the use of Large Language Models.**. Plagiarism is a form of academic misconduct and is taken very seriously by the University. Students found to have plagiarised work can have marks deducted and, in serious cases, even be expelled from the University. Do not submit any work that is not entirely your own. Do not collaborate with or get help from anybody else with this assignment.\n",
    "\n",
    "The University of Stirling's full policy on Academic Integrity can be found at:\n",
    "\n",
    "https://www.stir.ac.uk/about/professional-services/student-academic-and-corporate-services/academic-registry/academic-policy-and-practice/quality-handbook/academic-integrity-policy-and-academic-misconduct-procedure/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## The Assignment\n",
    "Your task with this assignment is to use the data provided to demonstrate your Python data manipulation skills.\n",
    "\n",
    "There are three `.csv` files and two `.json` files so you can process different types of data. The files also contain unstructured data in the form of natural language in English and links to images that you can access from the JC Penney website (use the field called `product_image_urls`).\n",
    "\n",
    "Start with easy tasks to show you can read in a file, create some variables and data structures, and manipulate their contents. Then move onto something more interesting.\n",
    "\n",
    "Look at the data that we provided with this assessment and think of something interesting to do with it using whatever libraries you like. Describe what you decide to do with the data and why it might be interesting or useful to the company to do it.\n",
    "\n",
    "You can add additional data if you need to - either download it or access it using `requests`. Produce working code to implement your ideas in as many cells as you need below. There is no single right answer, the aim is to simply show you are competent in using python for data analysis. Exactly how you do that is up to you.\n",
    "\n",
    "For a distinction class grade, this must show originality, creative thinking, and insights beyond what you've been taught directly on the module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Structure\n",
    "You may structure the appendix of the project how you wish, but here is a suggested guideline to help you organise your work, based on the CRISP-DM data science methodology:\n",
    "\n",
    " 1. **Business understanding** - What business context is the data coming from? What insights would be valuable in that context, and what data would be required for that purporse? \n",
    " 2. **Data understanding and preparation** - Explore the data and show you understand its structure and relations, with the aid of appropriate visualisation techniques. Assess the data quality, which insights you would be able to answer from it, and what preparation the data would require. Add new data from another source if required to bring new insights to the data you already have.\n",
    " 3. **Data modeling (optional)** - Would modeling be required for the insights you have considered? Use appropriate techniques, if so.\n",
    " 4. **Evaluation and deployment** - How do the insights you obtained help the company, and how can should they be adopted in their business? If modeling techniques have been adopted, are their use scientifically sound and how should they be mantained?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remember to make sure you are working completely on your own.\n",
    "# Don't work in a group or with a friend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code and comments in cells below here\n",
    "# Add as many cells as you need\n",
    "# Planing : revenue drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Planing :\n",
    "For 5 pages \n",
    "targetting insight for revenue drivers, product quality signals and customet sentiment, image-quality, merchandising checks and operational KPIs(returns, complaints and sesonality.\n",
    "\n",
    "Apendix:\n",
    "\n",
    "Code that reads the data files , data cleaning, exploratory analysis basic NLP sentiments and topic extraction and outputs with illustrative charts. Methods and alternatives are justified inline\n",
    "\n",
    "\n",
    "Business context:\n",
    "\n",
    "\n",
    "## Insight ideas:\n",
    "\n",
    "### Users based on age and state graph\n",
    "\n",
    "\n",
    "### Predict high return / refund likelihood\n",
    "\n",
    "\n",
    "### Seasonality & lead indicators a time series heatmaps\n",
    "Objective: Detect seasonal patterns in sales and review frequency to inform inventory & marketing timing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rinold/Documents/assignment-works/3079158-ITNPBD2-python\n",
      "\n",
      "products DataFrame: shape=(7982, 6)\n",
      "Columns: ['Uniq_id', 'SKU', 'Name', 'Description', 'Price', 'Av_Score']\n",
      "Head:\n",
      "                              Uniq_id           SKU  \\\n",
      "0   b6c0b6bea69c722939585baeac73c13d  pp5006380337   \n",
      "1   93e5272c51d8cce02597e3ce67b7ad0a  pp5006380337   \n",
      "2   013e320f2f2ec0cf5b3ff5418d688528  pp5006380337   \n",
      "3   505e6633d81f2cb7400c0cfa0394c427  pp5006380337   \n",
      "4   d969a8542122e1331e304b09f81a83f6  pp5006380337   \n",
      "5   cf73bb2bd93bbd6e1bdf48d399992270  pp5006380337   \n",
      "6   8ffd0ef4fcaf1a82fb514aba5d20e05b  pp5006790247   \n",
      "7   4d9337e3c8f974d3c420cdc5c58b3fc3  pp5007090172   \n",
      "8   44f8f8f108c6856acf9630dd1d78516d  pp5007080134   \n",
      "9   8d1d057f5f808c10ce243c222ab0ef6e  pp5007080134   \n",
      "10  f3e02c48f16b56e8c1f126c8fe762812  pp5007080134   \n",
      "11  5abf9d28e9e0404369ece10807d99d0e  pp5006790242   \n",
      "12  82d8a9a627e55ba97a1051068c9823e7  pp5006790242   \n",
      "\n",
      "                                                 Name  \\\n",
      "0         Alfred Dunner® Essential Pull On Capri Pant   \n",
      "1         Alfred Dunner® Essential Pull On Capri Pant   \n",
      "2         Alfred Dunner® Essential Pull On Capri Pant   \n",
      "3         Alfred Dunner® Essential Pull On Capri Pant   \n",
      "4         Alfred Dunner® Essential Pull On Capri Pant   \n",
      "5         Alfred Dunner® Essential Pull On Capri Pant   \n",
      "6   Alfred Dunner® Feels Like Spring 3/4 Sleeve Le...   \n",
      "7   Alfred Dunner® Feels Like Spring 3/4-Sleeve Le...   \n",
      "8   Alfred Dunner® Feels Like Spring 3/4-Sleeve Wa...   \n",
      "9   Alfred Dunner® Feels Like Spring 3/4-Sleeve Wa...   \n",
      "10  Alfred Dunner® Feels Like Spring 3/4-Sleeve Wa...   \n",
      "11            Alfred Dunner® Feels Like Spring Capris   \n",
      "12            Alfred Dunner® Feels Like Spring Capris   \n",
      "\n",
      "                                          Description  Price  Av_Score  \n",
      "0   Youll return to our Alfred Dunner pull-on capr...  41.09     2.625  \n",
      "1   Youll return to our Alfred Dunner pull-on capr...  41.09     3.000  \n",
      "2   Youll return to our Alfred Dunner pull-on capr...  41.09     2.625  \n",
      "3   Youll return to our Alfred Dunner pull-on capr...  41.09     3.500  \n",
      "4   Youll return to our Alfred Dunner pull-on capr...  41.09     3.125  \n",
      "5   Youll return to our Alfred Dunner pull-on capr...  41.09     3.000  \n",
      "6   For easygoing style youll love, wear our stret...  65.27     3.750  \n",
      "7   Spring is in the air with our 3/4-sleeve leaf ...    NaN     1.000  \n",
      "8                                                 NaN    NaN     4.500  \n",
      "9                                                 NaN    NaN     2.500  \n",
      "10                                                NaN    NaN     1.000  \n",
      "11  Pull on a pair of our casual capris and be foo...  58.01     4.800  \n",
      "12  Pull on a pair of our casual capris and be foo...  58.01     2.600  \n",
      "\n",
      "reviews DataFrame: shape=(39063, 4)\n",
      "Columns: ['Uniq_id', 'Username', 'Score', 'Review']\n",
      "Head:\n",
      "                              Uniq_id  Username  Score  \\\n",
      "0   b6c0b6bea69c722939585baeac73c13d  fsdv4141      2   \n",
      "1   b6c0b6bea69c722939585baeac73c13d  krpz1113      1   \n",
      "2   b6c0b6bea69c722939585baeac73c13d  mbmg3241      2   \n",
      "3   b6c0b6bea69c722939585baeac73c13d  zeqg1222      0   \n",
      "4   b6c0b6bea69c722939585baeac73c13d  nvfn3212      3   \n",
      "5   b6c0b6bea69c722939585baeac73c13d  aajh3423      2   \n",
      "6   b6c0b6bea69c722939585baeac73c13d  usvp2142      1   \n",
      "7   b6c0b6bea69c722939585baeac73c13d  yemw3321      1   \n",
      "8   93e5272c51d8cce02597e3ce67b7ad0a  tpcu2211      3   \n",
      "9   93e5272c51d8cce02597e3ce67b7ad0a  vutl2421      2   \n",
      "10  93e5272c51d8cce02597e3ce67b7ad0a  ixlo1324      0   \n",
      "11  93e5272c51d8cce02597e3ce67b7ad0a  dued2313      2   \n",
      "12  93e5272c51d8cce02597e3ce67b7ad0a  nkmn4113      1   \n",
      "\n",
      "                                               Review  \n",
      "0   You never have to worry about the fit...Alfred...  \n",
      "1   Good quality fabric. Perfect fit. Washed very ...  \n",
      "2   I do not normally wear pants or capris that ha...  \n",
      "3   I love these capris! They fit true to size and...  \n",
      "4   This product is very comfortable and the fabri...  \n",
      "5   I did not like the fabric. It is 100% polyeste...  \n",
      "6   What a great deal. Beautiful Pants. Its more t...  \n",
      "7   Alfred Dunner has great pants, good fit and ve...  \n",
      "8   You never have to worry about the fit...Alfred...  \n",
      "9   Good quality fabric. Perfect fit. Washed very ...  \n",
      "10  I do not normally wear pants or capris that ha...  \n",
      "11  I love these capris! They fit true to size and...  \n",
      "12  This product is very comfortable and the fabri...  \n",
      "\n",
      "users DataFrame: shape=(5000, 3)\n",
      "Columns: ['Username', 'DOB', 'State']\n",
      "Head:\n",
      "     Username         DOB                 State\n",
      "0   bkpn1412  31.07.1983                Oregon\n",
      "1   gqjs4414  27.07.1998         Massachusetts\n",
      "2   eehe1434  08.08.1950                 Idaho\n",
      "3   hkxj1334  03.08.1969               Florida\n",
      "4   jjbd1412  26.07.2001               Georgia\n",
      "5   rriz2231  08.08.1951               Montana\n",
      "6   dvmv4241  02.08.1975          Pennsylvania\n",
      "7   ibtk1124  31.07.1983           Connecticut\n",
      "8   ryqz4413  28.07.1992              Arkansas\n",
      "9   ezng1232  03.08.1968              Nebraska\n",
      "10  asfi3222  01.08.1977            California\n",
      "11  vsqn3242  29.07.1991         New Hampshire\n",
      "12  rjwh2331  31.07.1980  District of Columbia\n",
      "\n",
      "jc_reviewers DataFrame: shape=(5000, 4)\n",
      "Columns: ['Username', 'DOB', 'State', 'Reviewed']\n",
      "Head:\n",
      "     Username         DOB                 State  \\\n",
      "0   bkpn1412  31.07.1983                Oregon   \n",
      "1   gqjs4414  27.07.1998         Massachusetts   \n",
      "2   eehe1434  08.08.1950                 Idaho   \n",
      "3   hkxj1334  03.08.1969               Florida   \n",
      "4   jjbd1412  26.07.2001               Georgia   \n",
      "5   rriz2231  08.08.1951               Montana   \n",
      "6   dvmv4241  02.08.1975          Pennsylvania   \n",
      "7   ibtk1124  31.07.1983           Connecticut   \n",
      "8   ryqz4413  28.07.1992              Arkansas   \n",
      "9   ezng1232  03.08.1968              Nebraska   \n",
      "10  asfi3222  01.08.1977            California   \n",
      "11  vsqn3242  29.07.1991         New Hampshire   \n",
      "12  rjwh2331  31.07.1980  District of Columbia   \n",
      "\n",
      "                                             Reviewed  \n",
      "0                  [cea76118f6a9110a893de2b7654319c0]  \n",
      "1                  [fa04fe6c0dd5189f54fe600838da43d3]  \n",
      "2                                                  []  \n",
      "3   [f129b1803f447c2b1ce43508fb822810, 3b0c9bc0be6...  \n",
      "4                                                  []  \n",
      "5                  [b3b3343d6ee7662ea7decbce740196ea]  \n",
      "6   [68f724f2be6674413da9d3a39b951327, 33a8fe5231c...  \n",
      "7   [76242d553d8bd2b004eab36da5853016, 918493871af...  \n",
      "8   [7bad312be2bf333a96513ea443a7dab1, 8feb38562ef...  \n",
      "9   [53ebc7267caffd49e730d334714ec8b2, 91223d2aa5f...  \n",
      "10                 [fe2b5dab1da61710e8c3eb6d729d6a48]  \n",
      "11                 [ad6e00262a1424f5bfccd1a1c163d9e0]  \n",
      "12                                                 []  \n",
      "\n",
      "jc_products DataFrame: shape=(7982, 15)\n",
      "Columns: ['uniq_id', 'sku', 'name_title', 'description', 'list_price', 'sale_price', 'category', 'category_tree', 'average_product_rating', 'product_url', 'product_image_urls', 'brand', 'total_number_reviews', 'Reviews', 'Bought With']\n",
      "Head:\n",
      "                              uniq_id           sku  \\\n",
      "0   b6c0b6bea69c722939585baeac73c13d  pp5006380337   \n",
      "1   93e5272c51d8cce02597e3ce67b7ad0a  pp5006380337   \n",
      "2   013e320f2f2ec0cf5b3ff5418d688528  pp5006380337   \n",
      "3   505e6633d81f2cb7400c0cfa0394c427  pp5006380337   \n",
      "4   d969a8542122e1331e304b09f81a83f6  pp5006380337   \n",
      "5   cf73bb2bd93bbd6e1bdf48d399992270  pp5006380337   \n",
      "6   8ffd0ef4fcaf1a82fb514aba5d20e05b  pp5006790247   \n",
      "7   4d9337e3c8f974d3c420cdc5c58b3fc3  pp5007090172   \n",
      "8   44f8f8f108c6856acf9630dd1d78516d  pp5007080134   \n",
      "9   8d1d057f5f808c10ce243c222ab0ef6e  pp5007080134   \n",
      "10  f3e02c48f16b56e8c1f126c8fe762812  pp5007080134   \n",
      "11  5abf9d28e9e0404369ece10807d99d0e  pp5006790242   \n",
      "12  82d8a9a627e55ba97a1051068c9823e7  pp5006790242   \n",
      "\n",
      "                                           name_title  \\\n",
      "0         Alfred Dunner® Essential Pull On Capri Pant   \n",
      "1         Alfred Dunner® Essential Pull On Capri Pant   \n",
      "2         Alfred Dunner® Essential Pull On Capri Pant   \n",
      "3         Alfred Dunner® Essential Pull On Capri Pant   \n",
      "4         Alfred Dunner® Essential Pull On Capri Pant   \n",
      "5         Alfred Dunner® Essential Pull On Capri Pant   \n",
      "6   Alfred Dunner® Feels Like Spring 3/4 Sleeve Le...   \n",
      "7   Alfred Dunner® Feels Like Spring 3/4-Sleeve Le...   \n",
      "8   Alfred Dunner® Feels Like Spring 3/4-Sleeve Wa...   \n",
      "9   Alfred Dunner® Feels Like Spring 3/4-Sleeve Wa...   \n",
      "10  Alfred Dunner® Feels Like Spring 3/4-Sleeve Wa...   \n",
      "11            Alfred Dunner® Feels Like Spring Capris   \n",
      "12            Alfred Dunner® Feels Like Spring Capris   \n",
      "\n",
      "                                          description list_price sale_price  \\\n",
      "0   You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
      "1   You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
      "2   You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
      "3   You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
      "4   You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
      "5   You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
      "6   For easygoing style you'll love, wear our stre...      65.27      39.16   \n",
      "7   Spring is in the air with our 3/4-sleeve leaf ...                  70.1   \n",
      "8                                                                   62.8574   \n",
      "9                                                                   62.8574   \n",
      "10                                                                  62.8574   \n",
      "11  Pull on a pair of our casual capris and be foo...      58.01      34.81   \n",
      "12  Pull on a pair of our casual capris and be foo...      58.01      34.81   \n",
      "\n",
      "               category                       category_tree  \\\n",
      "0         alfred dunner        jcpenney|women|alfred dunner   \n",
      "1         alfred dunner        jcpenney|women|alfred dunner   \n",
      "2              view all             jcpenney|women|view all   \n",
      "3              view all             jcpenney|women|view all   \n",
      "4              view all             jcpenney|women|view all   \n",
      "5                 deals                jcpenney|shops|deals   \n",
      "6              view all             jcpenney|women|view all   \n",
      "7              skechers             jcpenney|women|skechers   \n",
      "8        search-results            jcpenney||search-results   \n",
      "9   outfits you'll love  jcpenney|women|outfits you'll love   \n",
      "10  outfits you'll love  jcpenney|women|outfits you'll love   \n",
      "11       capris & crops       jcpenney|women|capris & crops   \n",
      "12             view all             jcpenney|women|view all   \n",
      "\n",
      "    average_product_rating                                        product_url  \\\n",
      "0                    2.625  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
      "1                    3.000  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
      "2                    2.625  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
      "3                    3.500  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
      "4                    3.125  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
      "5                    3.000  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
      "6                    3.750  http://www.jcpenney.com/alfred-dunner-feels-li...   \n",
      "7                    1.000  http://www.jcpenney.com/alfred-dunner-feels-li...   \n",
      "8                    4.500  http://www.jcpenney.com/alfred-dunner-feels-li...   \n",
      "9                    2.500  http://www.jcpenney.com/alfred-dunner-feels-li...   \n",
      "10                   1.000  http://www.jcpenney.com/alfred-dunner-feels-li...   \n",
      "11                   4.800  http://www.jcpenney.com/alfred-dunner-feels-li...   \n",
      "12                   2.600  http://www.jcpenney.com/alfred-dunner-feels-li...   \n",
      "\n",
      "                                   product_image_urls          brand  \\\n",
      "0   http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
      "1   http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
      "2   http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
      "3   http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
      "4   http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
      "5   http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
      "6   http://s7d9.scene7.com/is/image/JCPenney/DP022...  Alfred Dunner   \n",
      "7   http://s7d9.scene7.com/is/image/JCPenney/DP033...  Alfred Dunner   \n",
      "8   http://s7d9.scene7.com/is/image/JCPenney/DP033...  Alfred Dunner   \n",
      "9   http://s7d9.scene7.com/is/image/JCPenney/DP033...  Alfred Dunner   \n",
      "10  http://s7d9.scene7.com/is/image/JCPenney/DP033...  Alfred Dunner   \n",
      "11  http://s7d9.scene7.com/is/image/JCPenney/DP022...  Alfred Dunner   \n",
      "12  http://s7d9.scene7.com/is/image/JCPenney/DP022...  Alfred Dunner   \n",
      "\n",
      "    total_number_reviews                                            Reviews  \\\n",
      "0                      8  [{'User': 'fsdv4141', 'Review': 'You never hav...   \n",
      "1                      8  [{'User': 'tpcu2211', 'Review': 'You never hav...   \n",
      "2                      8  [{'User': 'pcfg3234', 'Review': 'You never hav...   \n",
      "3                      8  [{'User': 'ngrq4411', 'Review': 'You never hav...   \n",
      "4                      8  [{'User': 'nbmi2334', 'Review': 'You never hav...   \n",
      "5                      8  [{'User': 'mewj3321', 'Review': 'You never hav...   \n",
      "6                      4  [{'User': 'glvx4212', 'Review': 'I loved the q...   \n",
      "7                      1  [{'User': 'vivj4111', 'Review': 'The colors an...   \n",
      "8                      2  [{'User': 'neqb2223', 'Review': 'I love the wa...   \n",
      "9                      2  [{'User': 'tyfr4414', 'Review': 'I love the wa...   \n",
      "10                     2  [{'User': 'jigo2232', 'Review': 'I love the wa...   \n",
      "11                     5  [{'User': 'gbir2423', 'Review': 'These capris ...   \n",
      "12                     5  [{'User': 'yrzj4331', 'Review': 'These capris ...   \n",
      "\n",
      "                                          Bought With  \n",
      "0   [898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...  \n",
      "1   [bc9ab3406dcaa84a123b9da862e6367d, 18eb69e8fc2...  \n",
      "2   [3ce70f519a9cfdd85cdbdecd358e5347, b0295c96d2b...  \n",
      "3   [efcd811edccbeb5e67eaa8ef0d991f7c, 7b2cc00171e...  \n",
      "4   [0ca5ad2a218f59eb83eec1e248a0782d, 9869fc8da14...  \n",
      "5   [fa181e36fe1286e311b2fc92e4db1fa8, f219d07e6d7...  \n",
      "6   [9de873d6c2137427230daaf3420bce49, fb74ceea621...  \n",
      "7   [ac1c58ca9f2d61a98f4f88ec4594bb9a, 88632e0cb0c...  \n",
      "8   [85540e6a399a84fd2dd06dfa4dfd0aa6, 95a9bca3c6a...  \n",
      "9   [d1f5ae198a202f75c39be4227ccbeaa7, 7719e568f20...  \n",
      "10  [9591c0a7ba5fd1be39d71628d1b22280, 4c5b6c0c8f6...  \n",
      "11  [d025ca125d34d44265a78cbc2b9aeee8, de618d6eb12...  \n",
      "12  [30ed453a015d54e29647a0a05273897e, 03f7fd54bcc...  \n"
     ]
    }
   ],
   "source": [
    "# Load files\n",
    "\n",
    "base_path = os.getcwd()\n",
    "print(base_path)\n",
    "product_csv_path = base_path + '/JCPenneyFile-work-1/products.csv';\n",
    "users_csv_path = base_path + '/JCPenneyFile-work-1/users.csv';\n",
    "reviews_csv_path = base_path + '/JCPenneyFile-work-1/reviews.csv';\n",
    "products_json_path = base_path + '/JCPenneyFile-work-1/jcpenney_products.json';\n",
    "reviewers_json_path = base_path + '/JCPenneyFile-work-1/jcpenney_reviewers.json';\n",
    "\n",
    "products_df = pd.read_csv(product_csv_path)\n",
    "reviews_df = pd.read_csv(reviews_csv_path)\n",
    "users_df = pd.read_csv(users_csv_path)\n",
    "\n",
    "# JSON loader as pandas DataFrame *starts*.\n",
    "# checks for json format issue and fixes it\n",
    "def load_json_df(path):\n",
    "    data = []\n",
    "    with open(path, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                 print(f\"catching invalid JSON line: {line.strip()}\")\n",
    "        return pd.DataFrame(data)\n",
    "        # If JSON is a list of objects -> DataFrame; otherwise return raw dict\n",
    "    if isinstance(data, list):\n",
    "        return pd.DataFrame(data)\n",
    "    else:\n",
    "        return pd.json_normalize(data)    \n",
    "# *Ends* JSON loader as pandas DataFrame.\n",
    "\n",
    "reviewers_json_df = load_json_df(reviewers_json_path)\n",
    "products_json_df = load_json_df(products_json_path)\n",
    "\n",
    "# File structure(shapes and colums) lookup\n",
    "for name, df in zip(['products', 'reviews', 'users', 'jc_reviewers', 'jc_products'],\n",
    "                    [products_df, reviews_df, users_df, reviewers_json_df, products_json_df]):\n",
    "    print(f\"\\n{name} DataFrame: shape={df.shape}\")\n",
    "    print(\"Columns:\", df.columns.tolist())\n",
    "    print(\"Head:\\n\", df.head(13))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- products ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7982 entries, 0 to 7981\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Uniq_id      7982 non-null   object \n",
      " 1   SKU          7915 non-null   object \n",
      " 2   Name         7982 non-null   object \n",
      " 3   Description  7439 non-null   object \n",
      " 4   Price        5816 non-null   float64\n",
      " 5   Av_Score     7982 non-null   float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 374.3+ KB\n",
      "None\n",
      "Missing values per column:\n",
      "Uniq_id           0\n",
      "SKU              67\n",
      "Name              0\n",
      "Description     543\n",
      "Price          2166\n",
      "Av_Score          0\n",
      "dtype: int64\n",
      "\n",
      "--- reviews ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39063 entries, 0 to 39062\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Uniq_id   39063 non-null  object\n",
      " 1   Username  39063 non-null  object\n",
      " 2   Score     39063 non-null  int64 \n",
      " 3   Review    39063 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.2+ MB\n",
      "None\n",
      "Missing values per column:\n",
      "Uniq_id     0\n",
      "Username    0\n",
      "Score       0\n",
      "Review      0\n",
      "dtype: int64\n",
      "\n",
      "--- users ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Username  5000 non-null   object\n",
      " 1   DOB       5000 non-null   object\n",
      " 2   State     5000 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 117.3+ KB\n",
      "None\n",
      "Missing values per column:\n",
      "Username    0\n",
      "DOB         0\n",
      "State       0\n",
      "dtype: int64\n",
      "\n",
      "--- jc_reviewers ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Username  5000 non-null   object\n",
      " 1   DOB       5000 non-null   object\n",
      " 2   State     5000 non-null   object\n",
      " 3   Reviewed  5000 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 156.4+ KB\n",
      "None\n",
      "Missing values per column:\n",
      "Username    0\n",
      "DOB         0\n",
      "State       0\n",
      "Reviewed    0\n",
      "dtype: int64\n",
      "\n",
      "--- jc_products ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7982 entries, 0 to 7981\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   uniq_id                 7982 non-null   object \n",
      " 1   sku                     7982 non-null   object \n",
      " 2   name_title              7982 non-null   object \n",
      " 3   description             7982 non-null   object \n",
      " 4   list_price              7982 non-null   object \n",
      " 5   sale_price              7982 non-null   object \n",
      " 6   category                7982 non-null   object \n",
      " 7   category_tree           7982 non-null   object \n",
      " 8   average_product_rating  7982 non-null   float64\n",
      " 9   product_url             7982 non-null   object \n",
      " 10  product_image_urls      7982 non-null   object \n",
      " 11  brand                   7982 non-null   object \n",
      " 12  total_number_reviews    7982 non-null   int64  \n",
      " 13  Reviews                 7982 non-null   object \n",
      " 14  Bought With             7982 non-null   object \n",
      "dtypes: float64(1), int64(1), object(13)\n",
      "memory usage: 935.5+ KB\n",
      "None\n",
      "Missing values per column:\n",
      "uniq_id                   0\n",
      "sku                       0\n",
      "name_title                0\n",
      "description               0\n",
      "list_price                0\n",
      "sale_price                0\n",
      "category                  0\n",
      "category_tree             0\n",
      "average_product_rating    0\n",
      "product_url               0\n",
      "product_image_urls        0\n",
      "brand                     0\n",
      "total_number_reviews      0\n",
      "Reviews                   0\n",
      "Bought With               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check info and missing values for each DataFrame\n",
    "def missingness_report(df, name):\n",
    "    print(f'\\n---------- {name} ----------')\n",
    "    print(df.info())  # types and nulls\n",
    "    print('Missing values per column:')\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "missingness_report(products_df, 'products')\n",
    "missingness_report(reviews_df, 'reviews')\n",
    "missingness_report(users_df, 'users')\n",
    "missingness_report(reviewers_json_df, 'jc_reviewers')\n",
    "missingness_report(products_json_df, 'jc_products')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Products_df, Rows with missing Price: 2166\n",
      "Shape after dropping NaN price: (5767, 6)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# cleaning the product dataframe\n",
    "price_missing_count = products_df['Price'].isnull().sum()\n",
    "print(f\"In Products_df, Rows with missing Price: {price_missing_count}\")\n",
    "\n",
    "# Drop rows where Price is NaN\n",
    "product_cleaned_df = products_df.dropna(subset=['Price','SKU','Description']).copy()\n",
    "\n",
    "# print new shape\n",
    "print(print(f\"Shape after dropping NaN price: {product_cleaned_df.shape}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['uniq_id', 'sku', 'name', 'description', 'price', 'av_score'], dtype='object')\n",
      "Index(['uniq_id', 'username', 'score', 'review'], dtype='object')\n",
      "Index(['username', 'dob', 'state'], dtype='object')\n",
      "Index(['username', 'dob', 'state', 'reviewed'], dtype='object')\n",
      "Index(['uniq_id', 'sku', 'name_title', 'description', 'list_price',\n",
      "       'sale_price', 'category', 'category_tree', 'average_product_rating',\n",
      "       'product_url', 'product_image_urls', 'brand', 'total_number_reviews',\n",
      "       'reviews', 'bought with'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#  standardize colun names\n",
    "def normalise_columns(df):\n",
    "    df.columns = df.columns.str.lower().str.strip()\n",
    "    return df\n",
    "\n",
    "dataframe_list = [product_cleaned_df, reviews_df, users_df, reviewers_json_df, products_json_df]\n",
    "dataframe_list = [normalise_columns(df) for df in dataframe_list]\n",
    "\n",
    "\n",
    "for df in dataframe_list:\n",
    "    # print(df.info())\n",
    "    print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
