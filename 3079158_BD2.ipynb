{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# University of Stirling\n",
    "\n",
    "# ITNPBD2 Representing and Manipulating Data\n",
    "\n",
    "# Assignment Autumn 2025\n",
    "\n",
    "# A Consultancy Job for JC Penney\n",
    "\n",
    "This notebook forms the assignment instructions and submission document of the assignment for ITNPBD2. Read the instructions carefully and enter code into the cells as indicated.\n",
    "\n",
    "You will need these five files, which were in the Zip file you downloaded from the course webpage:\n",
    "\n",
    "- jcpenney_reviewers.json\n",
    "- jcpenney_products.json\n",
    "- products.csv\n",
    "- reviews.csv\n",
    "- users.csv\n",
    "\n",
    "The data in these files describes products that have been sold by the American retail giant, JC Penney, and reviews by customers who bought them. Note that the product data is real, but the customer data is synthetic.\n",
    "\n",
    "Your job is to process the data, as requested in the instructions in the markdown cells in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Completing the Assignment\n",
    "\n",
    "Rename this file to be xxxxxx_BD2 where xxxxxx is your student number, then type your code and narrative description into the boxes provided. Add as many code and markdown cells as you need. The cells should contain:\n",
    "\n",
    "- **Text narrative describing what you did with the data**\n",
    "- **The code that performs the task you have described**\n",
    "- **Comments that explain your code**\n",
    "\n",
    "The final structure (in PDF) of your report must:\n",
    "- **Start from the main insights observed (max 5 pages)**\n",
    "- **Include as an appendix the source code used for producing those insights (max 15 pages)**\n",
    "- **Include an AI cover sheet (provided on Canvas), which must contain a link to a versioned notebook file in OneDrive or another platform for version checks.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marking Scheme\n",
    "The assessment will be marked against the university Common Marking Scheme (CMS)\n",
    "\n",
    "Here is a summary of what you need to achieve to gain a grade in the major grade bands:\n",
    "\n",
    "|Grade|Requirement|\n",
    "|:---|:---|\n",
    "| Fail | You will fail if your code does not run or does not achieve even the basics of the task. You may also fail if you submit code without either comments or a text explanation of what the code does.|\n",
    "| Pass | To pass, you must submit sufficient working code to show that you have mastered the basics of the task, even if not everything works completely. You must include some justifications for your choice of methods, but without mentioning alternatives. |\n",
    "| Merit | For a merit, your code must be mostly correct, with only small problems or parts missing, and your comments must be useful rather than simply re-stating the code in English. Most choices for methods and structures should be explained and alternatives mentioned. |\n",
    "| Distinction | For a distinction, your code must be working, correct, and well commented and shows an appreciation of style, efficiency and reliability. All choices for methods and structures are concisely justified and alternatives are given well thought considerations. For a distinction, your work should be good enough to present to executives at the company.|\n",
    "\n",
    "The full details of the CMS can be found here\n",
    "\n",
    "https://www.stir.ac.uk/about/professional-services/student-academic-and-corporate-services/academic-registry/academic-policy-and-practice/quality-handbook/assessment-policy-and-procedure/appendix-2-postgraduate-common-marking-scheme/\n",
    "\n",
    "Note that this means there are not certain numbers of marks allocated to each stage of the assignment. Your grade will reflect how well your solutions and comments demonstrate that you have achieved the learning outcomes of the task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "When you are ready to submit, **print** your notebook as PDF (go to File -> Print Preview) in the Jupyter menu. Make sure you have run all the cells and that their output is displayed. Any lines of code or comments that are not visible in the pdf should be broken across several lines. You can then submit the file online.\n",
    "\n",
    "Late penalties will apply at a rate of three marks per day, up to a maximum of 7 days. After 7 days you will be given a mark of 0. Extensions will be considered under acceptable circumstances outside your control.\n",
    "\n",
    "## Academic Integrity\n",
    "\n",
    "This is an individual assignment, and so all submitted work must be fully your own work.\n",
    "\n",
    "The University of Stirling is committed to protecting the quality and standards of its awards. Consequently, the University seeks to promote and nurture academic integrity, support staff academic integrity, and support students to understand and develop good academic skills that facilitate academic integrity.\n",
    "\n",
    "In addition, the University deals decisively with all forms of Academic Misconduct.\n",
    "\n",
    "Where a student does not act with academic integrity, their work or behaviour may demonstrate Poor Academic Practice or it may represent Academic Misconduct.\n",
    "\n",
    "### Poor Academic Practice\n",
    "\n",
    "Poor Academic Practice is defined as: \"The submission of any type of assessment with a lack of referencing or inadequate referencing which does not effectively acknowledge the origin of words, ideas, images, tables, diagrams, maps, code, sound and any other sources used in the assessment.\"\n",
    "\n",
    "### Academic Misconduct\n",
    "\n",
    "Academic Misconduct is defined as: \"any act or attempted act that does not demonstrate academic integrity and that may result in creating an unfair academic advantage for you or another person, or an academic disadvantage for any other member or member of the academic community.\"\n",
    "\n",
    "Plagiarism is presenting somebody else’s work as your own **and includes the use of artificial intelligence tools beyond AIAS Level 2 or the use of Large Language Models.**. Plagiarism is a form of academic misconduct and is taken very seriously by the University. Students found to have plagiarised work can have marks deducted and, in serious cases, even be expelled from the University. Do not submit any work that is not entirely your own. Do not collaborate with or get help from anybody else with this assignment.\n",
    "\n",
    "The University of Stirling's full policy on Academic Integrity can be found at:\n",
    "\n",
    "https://www.stir.ac.uk/about/professional-services/student-academic-and-corporate-services/academic-registry/academic-policy-and-practice/quality-handbook/academic-integrity-policy-and-academic-misconduct-procedure/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## The Assignment\n",
    "Your task with this assignment is to use the data provided to demonstrate your Python data manipulation skills.\n",
    "\n",
    "There are three `.csv` files and two `.json` files so you can process different types of data. The files also contain unstructured data in the form of natural language in English and links to images that you can access from the JC Penney website (use the field called `product_image_urls`).\n",
    "\n",
    "Start with easy tasks to show you can read in a file, create some variables and data structures, and manipulate their contents. Then move onto something more interesting.\n",
    "\n",
    "Look at the data that we provided with this assessment and think of something interesting to do with it using whatever libraries you like. Describe what you decide to do with the data and why it might be interesting or useful to the company to do it.\n",
    "\n",
    "You can add additional data if you need to - either download it or access it using `requests`. Produce working code to implement your ideas in as many cells as you need below. There is no single right answer, the aim is to simply show you are competent in using python for data analysis. Exactly how you do that is up to you.\n",
    "\n",
    "For a distinction class grade, this must show originality, creative thinking, and insights beyond what you've been taught directly on the module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Structure\n",
    "You may structure the appendix of the project how you wish, but here is a suggested guideline to help you organise your work, based on the CRISP-DM data science methodology:\n",
    "\n",
    " 1. **Business understanding** - What business context is the data coming from? What insights would be valuable in that context, and what data would be required for that purporse? \n",
    " 2. **Data understanding and preparation** - Explore the data and show you understand its structure and relations, with the aid of appropriate visualisation techniques. Assess the data quality, which insights you would be able to answer from it, and what preparation the data would require. Add new data from another source if required to bring new insights to the data you already have.\n",
    " 3. **Data modeling (optional)** - Would modeling be required for the insights you have considered? Use appropriate techniques, if so.\n",
    " 4. **Evaluation and deployment** - How do the insights you obtained help the company, and how can should they be adopted in their business? If modeling techniques have been adopted, are their use scientifically sound and how should they be mantained?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remember to make sure you are working completely on your own.\n",
    "# Don't work in a group or with a friend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code and comments in cells below here\n",
    "# Add as many cells as you need\n",
    "# Planing : revenue drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Planing :\n",
    "For 5 pages \n",
    "targetting insight for revenue drivers, product quality signals and customet sentiment, image-quality, merchandising checks and operational KPIs(returns, complaints and sesonality.\n",
    "\n",
    "Apendix:\n",
    "\n",
    "Code that reads the data files , data cleaning, exploratory analysis basic NLP sentiments and topic extraction and outputs with illustrative charts. Methods and alternatives are justified inline\n",
    "\n",
    "\n",
    "Business context:\n",
    "\n",
    "\n",
    "## Insight ideas:\n",
    "\n",
    "### Users based on age and state graph\n",
    "\n",
    "\n",
    "### Predict high return / refund likelihood\n",
    "\n",
    "\n",
    "### Seasonality & lead indicators a time series heatmaps\n",
    "Objective: Detect seasonal patterns in sales and review frequency to inform inventory & marketing timing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility Block\n",
    "\n",
    "import importlib.util\n",
    "\n",
    "def is_package_installed(package_name):\n",
    "    \"\"\"Check if a package is installed\"\"\"\n",
    "    package_spec = importlib.util.find_spec(package_name)\n",
    "    return package_spec is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os, json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "products DataFrame: shape=(7982, 6)\n",
      "Columns: ['Uniq_id', 'SKU', 'Name', 'Description', 'Price', 'Av_Score']\n",
      "Head:\n",
      "                             Uniq_id           SKU  \\\n",
      "0  b6c0b6bea69c722939585baeac73c13d  pp5006380337   \n",
      "1  93e5272c51d8cce02597e3ce67b7ad0a  pp5006380337   \n",
      "2  013e320f2f2ec0cf5b3ff5418d688528  pp5006380337   \n",
      "\n",
      "                                          Name  \\\n",
      "0  Alfred Dunner® Essential Pull On Capri Pant   \n",
      "1  Alfred Dunner® Essential Pull On Capri Pant   \n",
      "2  Alfred Dunner® Essential Pull On Capri Pant   \n",
      "\n",
      "                                         Description  Price  Av_Score  \n",
      "0  Youll return to our Alfred Dunner pull-on capr...  41.09     2.625  \n",
      "1  Youll return to our Alfred Dunner pull-on capr...  41.09     3.000  \n",
      "2  Youll return to our Alfred Dunner pull-on capr...  41.09     2.625  \n",
      "\n",
      "reviews DataFrame: shape=(39063, 4)\n",
      "Columns: ['Uniq_id', 'Username', 'Score', 'Review']\n",
      "Head:\n",
      "                             Uniq_id  Username  Score  \\\n",
      "0  b6c0b6bea69c722939585baeac73c13d  fsdv4141      2   \n",
      "1  b6c0b6bea69c722939585baeac73c13d  krpz1113      1   \n",
      "2  b6c0b6bea69c722939585baeac73c13d  mbmg3241      2   \n",
      "\n",
      "                                              Review  \n",
      "0  You never have to worry about the fit...Alfred...  \n",
      "1  Good quality fabric. Perfect fit. Washed very ...  \n",
      "2  I do not normally wear pants or capris that ha...  \n",
      "\n",
      "users DataFrame: shape=(5000, 3)\n",
      "Columns: ['Username', 'DOB', 'State']\n",
      "Head:\n",
      "    Username         DOB          State\n",
      "0  bkpn1412  31.07.1983         Oregon\n",
      "1  gqjs4414  27.07.1998  Massachusetts\n",
      "2  eehe1434  08.08.1950          Idaho\n",
      "\n",
      "jc_reviewers DataFrame: shape=(5000, 4)\n",
      "Columns: ['Username', 'DOB', 'State', 'Reviewed']\n",
      "Head:\n",
      "    Username         DOB          State                            Reviewed\n",
      "0  bkpn1412  31.07.1983         Oregon  [cea76118f6a9110a893de2b7654319c0]\n",
      "1  gqjs4414  27.07.1998  Massachusetts  [fa04fe6c0dd5189f54fe600838da43d3]\n",
      "2  eehe1434  08.08.1950          Idaho                                  []\n",
      "\n",
      "jc_products DataFrame: shape=(7982, 15)\n",
      "Columns: ['uniq_id', 'sku', 'name_title', 'description', 'list_price', 'sale_price', 'category', 'category_tree', 'average_product_rating', 'product_url', 'product_image_urls', 'brand', 'total_number_reviews', 'Reviews', 'Bought With']\n",
      "Head:\n",
      "                             uniq_id           sku  \\\n",
      "0  b6c0b6bea69c722939585baeac73c13d  pp5006380337   \n",
      "1  93e5272c51d8cce02597e3ce67b7ad0a  pp5006380337   \n",
      "2  013e320f2f2ec0cf5b3ff5418d688528  pp5006380337   \n",
      "\n",
      "                                    name_title  \\\n",
      "0  Alfred Dunner® Essential Pull On Capri Pant   \n",
      "1  Alfred Dunner® Essential Pull On Capri Pant   \n",
      "2  Alfred Dunner® Essential Pull On Capri Pant   \n",
      "\n",
      "                                         description list_price sale_price  \\\n",
      "0  You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
      "1  You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
      "2  You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
      "\n",
      "        category                 category_tree  average_product_rating  \\\n",
      "0  alfred dunner  jcpenney|women|alfred dunner                   2.625   \n",
      "1  alfred dunner  jcpenney|women|alfred dunner                   3.000   \n",
      "2       view all       jcpenney|women|view all                   2.625   \n",
      "\n",
      "                                         product_url  \\\n",
      "0  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
      "1  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
      "2  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
      "\n",
      "                                  product_image_urls          brand  \\\n",
      "0  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
      "1  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
      "2  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
      "\n",
      "   total_number_reviews                                            Reviews  \\\n",
      "0                     8  [{'User': 'fsdv4141', 'Review': 'You never hav...   \n",
      "1                     8  [{'User': 'tpcu2211', 'Review': 'You never hav...   \n",
      "2                     8  [{'User': 'pcfg3234', 'Review': 'You never hav...   \n",
      "\n",
      "                                         Bought With  \n",
      "0  [898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...  \n",
      "1  [bc9ab3406dcaa84a123b9da862e6367d, 18eb69e8fc2...  \n",
      "2  [3ce70f519a9cfdd85cdbdecd358e5347, b0295c96d2b...  \n"
     ]
    }
   ],
   "source": [
    "# *** Load assginment files ***\n",
    "\n",
    "#get the absolute path\n",
    "base_path = os.getcwd()\n",
    "\n",
    "#appendoing the base path to the targetted file to get the full path.\n",
    "product_csv_path = base_path + '/JCPenneyFile-work-1/products.csv';\n",
    "users_csv_path = base_path + '/JCPenneyFile-work-1/users.csv';\n",
    "reviews_csv_path = base_path + '/JCPenneyFile-work-1/reviews.csv';\n",
    "products_json_path = base_path + '/JCPenneyFile-work-1/jcpenney_products.json';\n",
    "reviewers_json_path = base_path + '/JCPenneyFile-work-1/jcpenney_reviewers.json';\n",
    "\n",
    "products_df = pd.read_csv(product_csv_path)\n",
    "reviews_df = pd.read_csv(reviews_csv_path)\n",
    "users_df = pd.read_csv(users_csv_path)\n",
    "\n",
    "# *** JSON loader as pandas DataFrame ***\n",
    "# Load the JSON files and handling the format issues if occures.\n",
    "def load_json_df(path):\n",
    "    data = []\n",
    "    with open(path, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                 print(f\"catching invalid JSON line: {line.strip()}\")\n",
    "        return pd.DataFrame(data)\n",
    "        # If JSON is a list of objects -> DataFrame; otherwise return raw dict\n",
    "    if isinstance(data, list):\n",
    "        return pd.DataFrame(data)\n",
    "    else:\n",
    "        return pd.json_normalize(data)\n",
    "\n",
    "reviewers_json_df = load_json_df(reviewers_json_path)\n",
    "products_json_df = load_json_df(products_json_path)\n",
    "\n",
    "# File structure lookup\n",
    "for name, df in zip(['products', 'reviews', 'users', 'jc_reviewers', 'jc_products'],\n",
    "                    [products_df, reviews_df, users_df, reviewers_json_df, products_json_df]):\n",
    "    print(f\"\\n{name} DataFrame: shape={df.shape}\")\n",
    "    print(\"Columns:\", df.columns.tolist())\n",
    "    print(\"Head:\\n\", df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- INFO: products ----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7982 entries, 0 to 7981\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Uniq_id      7982 non-null   object \n",
      " 1   SKU          7915 non-null   object \n",
      " 2   Name         7982 non-null   object \n",
      " 3   Description  7439 non-null   object \n",
      " 4   Price        5816 non-null   float64\n",
      " 5   Av_Score     7982 non-null   float64\n",
      "dtypes: float64(2), object(4)\n",
      "memory usage: 374.3+ KB\n",
      "None\n",
      "Uniq_id : <class 'str'>\n",
      "SKU : <class 'str'>\n",
      "Name : <class 'str'>\n",
      "Description : <class 'str'>\n",
      "Price : <class 'str'>\n",
      "Av_Score : <class 'str'>\n",
      "Missing values per column:\n",
      "Uniq_id           0\n",
      "SKU              67\n",
      "Name              0\n",
      "Description     543\n",
      "Price          2166\n",
      "Av_Score          0\n",
      "dtype: int64\n",
      "\n",
      "---------- INFO: reviews ----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39063 entries, 0 to 39062\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   uniq_id   39063 non-null  object\n",
      " 1   username  39063 non-null  object\n",
      " 2   score     39063 non-null  int64 \n",
      " 3   review    39063 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.2+ MB\n",
      "None\n",
      "uniq_id : <class 'str'>\n",
      "username : <class 'str'>\n",
      "score : <class 'str'>\n",
      "review : <class 'str'>\n",
      "Missing values per column:\n",
      "uniq_id     0\n",
      "username    0\n",
      "score       0\n",
      "review      0\n",
      "dtype: int64\n",
      "\n",
      "---------- INFO: users ----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   username  5000 non-null   object\n",
      " 1   dob       5000 non-null   object\n",
      " 2   state     5000 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 117.3+ KB\n",
      "None\n",
      "username : <class 'str'>\n",
      "dob : <class 'str'>\n",
      "state : <class 'str'>\n",
      "Missing values per column:\n",
      "username    0\n",
      "dob         0\n",
      "state       0\n",
      "dtype: int64\n",
      "\n",
      "---------- INFO: jc_reviewers ----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   username  5000 non-null   object\n",
      " 1   dob       5000 non-null   object\n",
      " 2   state     5000 non-null   object\n",
      " 3   reviewed  5000 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 156.4+ KB\n",
      "None\n",
      "username : <class 'str'>\n",
      "dob : <class 'str'>\n",
      "state : <class 'str'>\n",
      "reviewed : <class 'str'>\n",
      "Missing values per column:\n",
      "username    0\n",
      "dob         0\n",
      "state       0\n",
      "reviewed    0\n",
      "dtype: int64\n",
      "\n",
      "---------- INFO: jc_products ----------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7982 entries, 0 to 7981\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   uniq_id                 7982 non-null   object \n",
      " 1   sku                     7982 non-null   object \n",
      " 2   name_title              7982 non-null   object \n",
      " 3   description             7982 non-null   object \n",
      " 4   list_price              7982 non-null   object \n",
      " 5   sale_price              7982 non-null   object \n",
      " 6   category                7982 non-null   object \n",
      " 7   category_tree           7982 non-null   object \n",
      " 8   average_product_rating  7982 non-null   float64\n",
      " 9   product_url             7982 non-null   object \n",
      " 10  product_image_urls      7982 non-null   object \n",
      " 11  brand                   7982 non-null   object \n",
      " 12  total_number_reviews    7982 non-null   int64  \n",
      " 13  reviews                 7982 non-null   object \n",
      " 14  bought with             7982 non-null   object \n",
      "dtypes: float64(1), int64(1), object(13)\n",
      "memory usage: 935.5+ KB\n",
      "None\n",
      "uniq_id : <class 'str'>\n",
      "sku : <class 'str'>\n",
      "name_title : <class 'str'>\n",
      "description : <class 'str'>\n",
      "list_price : <class 'str'>\n",
      "sale_price : <class 'str'>\n",
      "category : <class 'str'>\n",
      "category_tree : <class 'str'>\n",
      "average_product_rating : <class 'str'>\n",
      "product_url : <class 'str'>\n",
      "product_image_urls : <class 'str'>\n",
      "brand : <class 'str'>\n",
      "total_number_reviews : <class 'str'>\n",
      "reviews : <class 'str'>\n",
      "bought with : <class 'str'>\n",
      "Missing values per column:\n",
      "uniq_id                   0\n",
      "sku                       0\n",
      "name_title                0\n",
      "description               0\n",
      "list_price                0\n",
      "sale_price                0\n",
      "category                  0\n",
      "category_tree             0\n",
      "average_product_rating    0\n",
      "product_url               0\n",
      "product_image_urls        0\n",
      "brand                     0\n",
      "total_number_reviews      0\n",
      "reviews                   0\n",
      "bought with               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check info and missing values for each DataFrame\n",
    "def missingness_report(df, name):\n",
    "    print(f'\\n---------- INFO: {name} ----------')\n",
    "    print(df.info())  # types and nulls\n",
    "    for col in df.columns:\n",
    "        print(f'{col} : {type(col)}')\n",
    "    print('Missing values per column:')\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "missingness_report(products_df, 'products')\n",
    "missingness_report(reviews_df, 'reviews')\n",
    "missingness_report(users_df, 'users')\n",
    "missingness_report(reviewers_json_df, 'jc_reviewers')\n",
    "missingness_report(products_json_df, 'jc_products')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Products_df, Rows with missing Price: 2166\n",
      "Shape after dropping NaN price: (5767, 6)\n",
      "None\n",
      "Uniq_id        0\n",
      "SKU            0\n",
      "Name           0\n",
      "Description    0\n",
      "Price          0\n",
      "Av_Score       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# cleaning the product dataframe\n",
    "price_missing_count = products_df['Price'].isnull().sum()\n",
    "print(f\"In Products_df, Rows with missing Price: {price_missing_count}\")\n",
    "\n",
    "# Drop rows where Price is NaN\n",
    "product_cleaned_df = products_df.dropna(subset=['Price','SKU','Description']).copy()\n",
    "\n",
    "# print new shape\n",
    "print(print(f\"Shape after dropping NaN price: {product_cleaned_df.shape}\"))\n",
    "print(product_cleaned_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['uniq_id', 'sku', 'name', 'description', 'price', 'av_score'], dtype='object')\n",
      "Index(['uniq_id', 'username', 'score', 'review'], dtype='object')\n",
      "Index(['username', 'dob', 'state'], dtype='object')\n",
      "Index(['username', 'dob', 'state', 'reviewed'], dtype='object')\n",
      "Index(['uniq_id', 'sku', 'name_title', 'description', 'list_price',\n",
      "       'sale_price', 'category', 'category_tree', 'average_product_rating',\n",
      "       'product_url', 'product_image_urls', 'brand', 'total_number_reviews',\n",
      "       'reviews', 'bought with'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#  standardize colun names\n",
    "def normalise_columns(df):\n",
    "    df.columns = df.columns.str.lower().str.strip()\n",
    "    return df\n",
    "\n",
    "dataframe_list = [product_cleaned_df, reviews_df, users_df, reviewers_json_df, products_json_df]\n",
    "norm_dataframe_lis = [normalise_columns(df) for df in dataframe_list]\n",
    "\n",
    "\n",
    "for df in norm_dataframe_lis:\n",
    "    # print(df.info())\n",
    "    print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            uniq_id           sku  \\\n",
      "0  b6c0b6bea69c722939585baeac73c13d  pp5006380337   \n",
      "1  93e5272c51d8cce02597e3ce67b7ad0a  pp5006380337   \n",
      "\n",
      "                                    name_title  \\\n",
      "0  Alfred Dunner® Essential Pull On Capri Pant   \n",
      "1  Alfred Dunner® Essential Pull On Capri Pant   \n",
      "\n",
      "                                         description list_price sale_price  \\\n",
      "0  You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
      "1  You'll return to our Alfred Dunner pull-on cap...      41.09      24.16   \n",
      "\n",
      "        category                 category_tree  average_product_rating  \\\n",
      "0  alfred dunner  jcpenney|women|alfred dunner                   2.625   \n",
      "1  alfred dunner  jcpenney|women|alfred dunner                   3.000   \n",
      "\n",
      "                                         product_url  \\\n",
      "0  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
      "1  http://www.jcpenney.com/alfred-dunner-essentia...   \n",
      "\n",
      "                                  product_image_urls          brand  \\\n",
      "0  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
      "1  http://s7d9.scene7.com/is/image/JCPenney/DP122...  Alfred Dunner   \n",
      "\n",
      "   total_number_reviews                                            reviews  \\\n",
      "0                     8  [{'User': 'fsdv4141', 'Review': 'You never hav...   \n",
      "1                     8  [{'User': 'tpcu2211', 'Review': 'You never hav...   \n",
      "\n",
      "                                         bought with  \n",
      "0  [898e42fe937a33e8ce5e900ca7a4d924, 8c02c262567...  \n",
      "1  [bc9ab3406dcaa84a123b9da862e6367d, 18eb69e8fc2...  \n"
     ]
    }
   ],
   "source": [
    " print(products_json_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # You'll need to install matplotlib_venn first: pip install matplotlib-venn\n",
    "# # !pip install matplotlib-venn\n",
    "\n",
    "# # Check if matplotlib_venn is installed\n",
    "# if not is_package_installed('matplotlib_venn'):\n",
    "#     print(\"matplotlib_venn is not installed. Installing now...\")\n",
    "#     !pip install matplotlib-venn\n",
    "    \n",
    "\n",
    "# from matplotlib_venn import venn2\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Sets of IDs to compare (from your cleaned, normalized DataFrames)\n",
    "# product_ids = set(product_cleaned_df['uniq_id'])\n",
    "# review_ids = set(reviews_df['uniq_id'])\n",
    "\n",
    "# # Plot Venn diagram\n",
    "# plt.figure(figsize=(9,9))\n",
    "# venn2([product_ids, review_ids], set_labels=('Products','Reviews'))\n",
    "# plt.title('Overlap of uniq_id in Products and Reviews')\n",
    "# plt.show()\n",
    "# only_products = len(product_ids - review_ids)\n",
    "# only_reviews = len(review_ids - product_ids)\n",
    "# both = len(product_ids & review_ids)\n",
    "# print(f\"Products only: {only_products}\\nReviews only: {only_reviews}\\nBoth: {both}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
